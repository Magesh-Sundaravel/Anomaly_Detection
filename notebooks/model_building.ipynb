{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e03b49c-9aa1-4a05-bb3b-f39609817834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "299ff704-0fdf-4a4b-9ef6-df930db0e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "    def __init__(self):\n",
    "        self.data_path = data_path\n",
    "        self.full_data = self.csv_files()\n",
    "\n",
    "    def csv_files(self):\n",
    "        csv_files = [_ for _ in os.listdir(self.data_path) if _.endswith('.csv')]\n",
    "        data_frames = []\n",
    "\n",
    "        for idx,file in enumerate(csv_files):\n",
    "            data = pd.read_csv(os.path.join(self.data_path,file))\n",
    "            data['Timestamp'] = pd.to_datetime(data['Timestamp'],dayfirst=True)\n",
    "            data = data.rename(columns={data.columns[2]:'synthetic_data'})\n",
    "            data['Anomaly'] = data['Anomaly'].astype('int64')\n",
    "            data  = data.drop('original_signal',axis=1)\n",
    "            data_frames.append(data)\n",
    "\n",
    "        full_data = pd.concat(data_frames,ignore_index=True) \n",
    "        return full_data\n",
    "\n",
    "    def display_null_count_and_dtypes(self):\n",
    "        # Display the null counts\n",
    "        null_counts = self.full_data.isnull().sum()\n",
    "        print(f'Null Count:')\n",
    "        for col, count in null_counts.items():\n",
    "            print(f'{col}: {count}')\n",
    "        \n",
    "        print(f'\\nData Types:')\n",
    "        data_types = self.full_data.dtypes\n",
    "        for col, dtype in data_types.items():\n",
    "            print(f'{col}: {dtype}')\n",
    "\n",
    "    def period_of_time(self):\n",
    "        date_min = self.full_data['Timestamp'].min()\n",
    "        date_max = self.full_data['Timestamp'].max()\n",
    "        date_range = (date_max - date_min).days  \n",
    "        \n",
    "        print(f'\\nDate Range:')\n",
    "        print(f'Start:\\t{date_min}')\n",
    "        print(f'End:\\t{date_max}')\n",
    "        print(f'Days:\\t{date_range} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d791e274-d369-44c7-ac82-da1bab3f4c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Date Range:\n",
      "Start:\t2023-05-11 00:10:00\n",
      "End:\t2023-06-10 11:10:00\n",
      "Days:\t30 days\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/media/magesh/HardDisk/Thesis/anomaly_detection/data/processed/ml_data\"\n",
    "\n",
    "data = LoadData()\n",
    "\n",
    "data.period_of_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c74619-3cbc-4756-9673-edd3a224fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Timestamp'] = pd.to_datetime(combined_df['Timestamp'],dayfirst=True)\n",
    "combined_df['Day'] = combined_df['Timestamp'].dt.day\n",
    "combined_df['Month'] = combined_df['Timestamp'].dt.month\n",
    "combined_df['Year'] = combined_df['Timestamp'].dt.year\n",
    "combined_df['Hour'] = combined_df['Timestamp'].dt.hour\n",
    "combined_df['Minute'] = combined_df['Timestamp'].dt.minute\n",
    "\n",
    "\n",
    "columns_order = ['Day', 'Month', 'Year', 'Hour', 'Minute', 'synthetic_signal',\n",
    "                 'step_variable_ws5', 'step_variable_ws10', 'step_variable_ws15',\n",
    "                 'std_anomaly_ws5', 'std_anomaly_ws10', 'std_anomaly_ws15',\n",
    "                 'iqr_anomaly_ws5', 'iqr_anomaly_ws10', 'iqr_anomaly_ws15',\n",
    "                 'Anomaly']\n",
    "\n",
    "combined_df = combined_df[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d792ce-a432-40a2-8d1d-0314de054fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f1dc4-74c3-4991-952f-61f1f6305564",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=combined_df, x='Anomaly', palette='viridis')  \n",
    "\n",
    "labels = (combined_df.Anomaly.value_counts().values)\n",
    "\n",
    "for bar, label in zip(ax.patches, labels):\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f'{label}',\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.title('Count of Anomalies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef5a9d-c447-4815-8afe-de2618e5f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df.drop('Anomaly',axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0a3d6-f1c1-4918-8784-cfea32a20cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = combined_df['Anomaly']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22de69-6e5d-4198-80d8-436412b34ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y) # 0.8 / 0.2 = 1\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ffd17e-9dba-4099-8833-72fd9780ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_val.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8fa1d-da37-409e-a867-c6a1b8d10566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_model(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Initialize and train the model\n",
    "    model = SVC()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validate the model\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_accuracy = roc_auc_score(y_val, y_val_pred)\n",
    "    print(f\"Validation ROC score: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = roc_auc_score(y_test, y_test_pred)\n",
    "    print(f\"Test ROC score: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Print additional metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "# This is simple SVC Model\n",
    "model = build_simple_model(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ae219-4ce1-491d-a8d1-5871a4a03840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_model(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Initialize and train the model\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validate the model\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_accuracy = roc_auc_score(y_val, y_val_pred)\n",
    "    print(f\"Validation ROC score: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = roc_auc_score(y_test, y_test_pred)\n",
    "    print(f\"Test ROC score: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Print additional metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Simple Random Forest CLassifier Model\n",
    "model = build_simple_model(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6e929-f613-4928-8594-6c43aced0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_scaler(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    \n",
    "    # Create a pipeline with scaling and model\n",
    "    model = Pipeline(\n",
    "        [ ('scaler',RobustScaler()),\n",
    "        ('svc',SVC())\n",
    "        ]\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validate the model\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_accuracy = roc_auc_score(y_val, y_val_pred)\n",
    "    print(f\"Validation ROC score: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = roc_auc_score(y_test, y_test_pred)\n",
    "    print(f\"Test ROC score: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Print additional metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "# SVC model with Robust Scaler\n",
    "model = build_model_scaler(X_train, X_val, X_test, y_train, y_val, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee282b3a-7009-4ef8-86c8-ed10f1638bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_hyperparameter_tuning(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Define a parameter grid for RandomizedSearchCV\n",
    "    param_grid = {\n",
    "        'svc__C': [0.1, 1, 10, 100],\n",
    "        'svc__kernel': ['linear', 'rbf'],\n",
    "        'svc__class_weight': [None, 'balanced']\n",
    "    }\n",
    "    \n",
    "    # Construct the pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('svc', SVC(probability=True))\n",
    "    ])\n",
    "    \n",
    "    # Set up RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(pipe, param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    # Train the model with RandomizedSearchCV\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model from RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    # Make predictions on validation data\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    val_accuracy = roc_auc_score(y_val, y_val_pred)\n",
    "    print(f\"Validation ROC score: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Test the model\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = roc_auc_score(y_test, y_test_pred)\n",
    "    print(f\"Test ROC score: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Print additional metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(f\"Best SVC Hyperparameters: {random_search.best_params_}\")\n",
    "    return best_model\n",
    "\n",
    "# SVC model With Hyper Parameter Tuning:\n",
    "best_model = build_model_with_hyperparameter_tuning(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba43a0-ee50-4143-a358-1552305c4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_hyperparameter_tuning(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    \n",
    "    # Define a parameter grid for RandomizedSearchCV\n",
    "    param_grid = [{'n_estimators' : list(range(100,110)), \n",
    "                      'max_depth': list(range(10, 15)), \n",
    "                      'max_features': list(range(0,14))}\n",
    "                    ]\n",
    "    \n",
    "    # Initialize the model and RandomizedSearchCV\n",
    "    model = RandomForestClassifier()\n",
    "    random_search = RandomizedSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Train the model with RandomizedSearchCV\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model from RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    # Make predictions and evaluate\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    val_accuracy = roc_auc_score(y_val, y_pred)\n",
    "    print(f\"Validation ROC score: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = roc_auc_score(y_test, y_test_pred)\n",
    "    print(f\"Test ROC score: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Print additional metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Best RF Hyperparameters: {random_search.best_params_}\")\n",
    "    return best_model_\n",
    "\n",
    "rf_hyperparameter = build_model_with_hyperparameter_tuning(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "rf_hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246f6d6-9afd-4d08-bf14-f44173a518bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # # Calculate the ROC curve\n",
    "    # fpr, tpr, thresholds = roc_curve(y_test, y_test_probs)\n",
    "    \n",
    "    # # Plot the ROC curve\n",
    "    # plt.figure()\n",
    "    # plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    # plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "    # plt.xlim([0.0, 1.0])\n",
    "    # plt.ylim([0.0, 1.05])\n",
    "    # plt.xlabel('False Positive Rate')\n",
    "    # plt.ylabel('True Positive Rate')\n",
    "    # plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    # plt.legend(loc='lower right')\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
